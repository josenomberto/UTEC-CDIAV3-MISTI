{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josenomberto/UTEC-CDIAV3-MISTI/blob/main/day2_kobe_feature_engineering_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIbri09H8lNn"
      },
      "source": [
        "**If you haven't already, please hit :**\n",
        "\n",
        "`File` -> `Save a Copy in Drive`\n",
        "\n",
        "**to copy this notebook to your Google drive, and work on a copy. If you don't do this, your changes won't be saved!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering with the Kobe Bryant Dataset"
      ],
      "metadata": {
        "id": "yxh3f2fqE8R4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnwZfVHp8sCg"
      },
      "outputs": [],
      "source": [
        "# Import Packages\n",
        "\n",
        "# data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "\n",
        "# plots\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab as pl\n",
        "import seaborn as sns\n",
        "\n",
        "# scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# classification algorithms\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "\n",
        "# dimension reduction\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# cross-validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# model evaluation\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# text mining\n",
        "import re\n",
        "from nltk import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE: Explore the Kobe Bryant Dataset\n",
        "\n",
        "Explore the Kobe Bryant Dataset to understand what we may be able learn from it.\n",
        "\n",
        "Tasks:\n",
        "1. Get general information for the dataset using the methods `.head()`, `.tail()` and `.info()`.\n",
        "2. Identify if there are any missing values using the method `.isnull()`.\n",
        "3. Get summary statistics for the dataset using the method `.describe()`.\n",
        "4. Identify potential target variables in this dataset.\n",
        "5. Identify potential input features that could be used to predict your target variable."
      ],
      "metadata": {
        "id": "SVcD_mxZFU8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data as a pandas dataframe\n",
        "KobeDataset = pd.read_csv('KobeData.csv')\n",
        "print(\"Data dimensions:\" + str(KobeDataset.shape))"
      ],
      "metadata": {
        "id": "bhDZZxihGAA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TASK 1: Get General Information of Dataset"
      ],
      "metadata": {
        "id": "luLrK_pGHiAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 1 EXERCISE\n",
        "\n",
        "# Preview the first few rows\n",
        "print(\"\\n--- Head of the DataFrame ---\")\n",
        "''' ADD YOUR CODE HERE '''\n",
        "\n",
        "# Preview the last few rows\n",
        "print(\"\\n--- Tail of the DataFrame ---\")\n",
        "''' ADD YOUR CODE HERE '''\n",
        "\n",
        "# Check all columns and data types\n",
        "print(\"\\n--- DataFrame Info ---\")\n",
        "''' ADD YOUR CODE HERE '''\n",
        "\n",
        "# Add any additional methods of interest\n",
        "''' ADD YOUR CODE HERE '''"
      ],
      "metadata": {
        "id": "aN-4Z1o3HiKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TASK 2: Identify any missing data"
      ],
      "metadata": {
        "id": "GgcCpgkiIGn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 2 EXERCISE\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\n--- Missing Values ---\")\n",
        "''' ADD YOUR CODE HERE '''"
      ],
      "metadata": {
        "id": "zwG-zGHsIGum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TASK 3: Generate Summary Statistics"
      ],
      "metadata": {
        "id": "tw1046MeImqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 3 EXERCISE\n",
        "\n",
        "# Get summary statistics for numeric columns\n",
        "print(\"\\n--- Summary Statistics (Numeric) ---\")\n",
        "''' ADD YOUR CODE HERE '''"
      ],
      "metadata": {
        "id": "Y7qJ0ZC6Imz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore Data Types"
      ],
      "metadata": {
        "id": "Oif54hOICV0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will narrow our focus to only the 15 features listed above\n",
        "KobeDataset = KobeDataset.filter([\"action_type\", \"loc_x\", \"loc_y\",\"shot_distance\", \"shot_zone_basic\", \"shot_zone_area\", \"shot_type\",\n",
        "                                  \"period\", \"minutes_remaining\", \"seconds_remaining\", \"playoffs\", \"season\", \"game_date\",\"matchup\", \"shot_made_flag\"])\n",
        "\n",
        "print(\"Filtered Data dimensions:\" + str(KobeDataset.shape))\n",
        "\n",
        "# display the first 10 lines\n",
        "display(KobeDataset.head(10))"
      ],
      "metadata": {
        "id": "nyl_ULVrqHFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use .iloc to see single rows at a time, and .unique() to see the unique values in a feature\n",
        "\n",
        "display(KobeDataset['action_type'].unique())\n",
        "print()\n",
        "KobeDataset.iloc[[2]]"
      ],
      "metadata": {
        "id": "VpK8TyIbA543"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** From the Kobe Bryant dataset, what column could be used as the output label, and what columns could be used as input features?"
      ],
      "metadata": {
        "id": "hC3vQTH6oFbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "Dh2COIZcoOOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXERCISE: Identify Feature Data Types\n",
        "\n",
        "Identify the python data types of the following variables and their respective data type categories using the `.dtype` attribute as depicted in the following concept. Remember to print out examples using the method `.sample(~)` to help you identify the data types in more detail.\n",
        "\n",
        "Tasks:\n",
        "1. Identify the datatype of the feature `loc_x`. Print some samples from the dataframe.\n",
        "2. Identify the datatype of the feature `action_type`. Print some samples from the dataframe.\n",
        "3. Identify the datatype of the feature `playoffs`. Print some samples from the dataframe."
      ],
      "metadata": {
        "id": "5VFDp7dnuBSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 1: Identify the Data Type of `loc_x`"
      ],
      "metadata": {
        "id": "vQnxkAQ1J2MA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 1 EXERCISE\n",
        "\n",
        "# Identify the Data Type\n",
        "datatype_loc_x = <REPLACE ME AND MY ARROWS>\n",
        "print(\"Data type of loc_x: \", datatype_loc_x)\n",
        "\n",
        "# Print 5 values of the column\n",
        "print(\"\\n--- Sample 'loc_x' values ---\")\n",
        "print(<REPLACE ME AND MY ARROWS>)"
      ],
      "metadata": {
        "id": "mpX15MWUJ2Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 2: Identify the Data Type of `action_type`"
      ],
      "metadata": {
        "id": "f75q-jSMJ2rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 2 EXERCISE\n",
        "\n",
        "# Identify the Data Type\n",
        "datatype_action_type = <REPLACE ME AND MY ARROWS>\n",
        "print(\"Data type of action_type: \", datatype_action_type)\n",
        "\n",
        "# Print 5 values of the column\n",
        "print(\"\\n--- Sample 'action_type' values ---\")\n",
        "print(<REPLACE ME AND MY ARROWS>)"
      ],
      "metadata": {
        "id": "g087KfSZJ22P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 3: Identify the Data Type of `playoffs`"
      ],
      "metadata": {
        "id": "hxb_BgpRJ3K_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 3 EXERCISE\n",
        "\n",
        "# Identify the Data Type\n",
        "datatype_playoffs = <REPLACE ME AND MY ARROWS>\n",
        "print(\"Data type of playoffs: \", datatype_playoffs)\n",
        "\n",
        "# Print 5 values of the column\n",
        "print(\"\\n--- Sample 'playoffs' values ---\")\n",
        "print(KobeDataset['playoffs'].sample(5))"
      ],
      "metadata": {
        "id": "87X7JnruJ3SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** What are the different Python data types and more specifically, what are the data type categories for loc_x, action_type, and playoffs?"
      ],
      "metadata": {
        "id": "JlgDkS6BoW30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "YB5F-CCZobrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-Processing"
      ],
      "metadata": {
        "id": "nR5mclt7vWZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXERCISE: Data Pre-Processing with Typecasting and Removing Missing Data\n",
        "\n",
        "Now we will practice data pre-processing techniques essential for preparing our dataset for analysis, including handling missing values and converting data types to appropriate formats.\n",
        "\n",
        "Tasks:\n",
        "1. First, we will practice typecasting some of the features. Here, we focus on `game_date`. This is a date column which is in a string format. Convert this column into a datetime format using the `pd.to_datetime(~).dt.date` method. This method retains only the date part of the feature, which is relevant here, as there is no time portion to the feature. Has the minimum date value changed? Has the python datatype printout (`.dtypes(~)`) changed?\n",
        "2. Address the missing data points in this dataset. First, remove all of the rows where there is missing data in our target `shot_made_flag`. Next, replace the `NaN` values in `shot_distance` column with the mean of the column."
      ],
      "metadata": {
        "id": "-QiNeU_2sXIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 1: Perform Typecasting"
      ],
      "metadata": {
        "id": "xkwGhZlOQCn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prior to typecasting, the following fields with dates look like this:\n",
        "print(\"minimum game_date before typecasting is: \", KobeDataset['game_date'].min(axis=0))\n",
        "KobeDataset.dtypes['game_date']"
      ],
      "metadata": {
        "id": "pNtfa0SmRp_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 1 EXERCISE\n",
        "\n",
        "# Convert the column to datetime format\n",
        "KobeDataset['game_date'] = <REPLACE ME AND MY ARROWS>\n",
        "\n",
        "# Check what the minimum date is after updating the date format\n",
        "print(\"minimum game_date after typecasting is: \", KobeDataset['game_date'].min(axis=0), \"\\n\")\n",
        "\n",
        "# Notice that the python data type has not changed visibly, but a lot has changed under the hood\n",
        "KobeDataset.dtypes['game_date']"
      ],
      "metadata": {
        "id": "Khdfe3UNT1Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** Why is typecasting to a date type necessary for the columns which have date information?"
      ],
      "metadata": {
        "id": "aAioBahSqTdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "Brv_GEFJqVKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 2: Address Missing Data\n",
        "\n",
        "Next, lets check for missing data\n",
        "Missing data in this dataset is represented by nan values (as opposed to blanks, \"?\", etc)\n",
        "This is convenient for data stored in a pandas dataframe.\n",
        "\n",
        "If you look at the output of `KobeDataset.info()`, you will see that, we have exactly 5000 nulls in our dependent variable.\n",
        "\n",
        "As a data scientist, whenever you see such a round number for anything, you should be suspicious! *Why would the dataset be missing EXACTLY 5000 values?*\n",
        "\n",
        "In this case, these values were removed for the purposes of competition on Kaggle.com, to be evaluated as the competitors' test set. Since this is our dependent variable, we don't have much choice but to remove the 5000 records. Remove the 5000 records in the `shot_made_flag` column by using `.loc(~)`,\n",
        "filtering for all the rows with non-null values. Let's check that exactly 5000 were removed.\n",
        "\n",
        "Finally, replace the `NaN` value in the `shot_distance` column with the mean value using the `.fillna(~, inplace = True)` substituting \"~\" for the mean column value."
      ],
      "metadata": {
        "id": "VXtZ1Tk3szHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 2 EXERCISE\n",
        "\n",
        "# Look at Data\n",
        "KobeDataset.info()\n",
        "print('\\n')\n",
        "FullLength = len(KobeDataset)\n",
        "\n",
        "# Remove the Missing Rows and then Save This Updated Dataframe to KobeDataset\n",
        "KobeDataset = <REPLACE ME AND MY ARROWS>\n",
        "print(\"Removed\", FullLength - len(KobeDataset), \"records with null shot_made flag\")\n",
        "\n",
        "# Replace the Nans in `shot_distance` with the mean of the column\n",
        "'''ADD YOUR CODE HERE'''"
      ],
      "metadata": {
        "id": "3vS-6jnbtoDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Data"
      ],
      "metadata": {
        "id": "fu_IBuc3CDv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency table for how many datapoints have a specific category and label\n",
        "pd.crosstab(KobeDataset[\"shot_zone_basic\"], KobeDataset[\"shot_made_flag\"])"
      ],
      "metadata": {
        "id": "N46cQrTk59S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a plot of the table above\n",
        "pd.crosstab(KobeDataset['shot_zone_basic'], KobeDataset['shot_made_flag']).plot(kind=\"bar\");"
      ],
      "metadata": {
        "id": "qLQrLFGI6aCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJxUe6D3mCFX"
      },
      "source": [
        "For numerical features, we don't have categories that we can use as the x-axis. But we can split the datapoints into bins, such as 0.0 to 0.1 and look at the number of 0 and 1 labels for that bin."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For numerical variables, we can bin the amounts and check frequency of labels within each bin\n",
        "pd.crosstab(pd.cut(KobeDataset[\"seconds_remaining\"], bins= 5), KobeDataset['shot_made_flag']).plot(kind= \"bar\")"
      ],
      "metadata": {
        "id": "JPAeS01F74Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXERCISE: Visualize some of our data\n",
        "\n",
        "Let's now visualize some of our features. Make additional plots of additional features as time allows.\n",
        "\n",
        "Tasks:\n",
        "1. Make a plot to visualize the feature `shot_distance` in relation to the target variable `shot_made_flag`. First, define the bin bounds as the minimum value, 6, 10, 15, 20, 25, and the maximum value. Next, use `pd.cut(~)` to split the data into those bins. Next, use `pd.crosstab(~)` to compute a simple cross tabulation. A cross tabulation (often called a crosstab) is a table that shows the relationship between two or more categorical variables by counting how many observations fall into each combination of categories. Plot this crosstab using `crosstab_result.plot(~)`.\n",
        "2. Make a plot to visualize the feature `shot_distance` in relation to the target variable `shot_made_flag`. This should be much easier than making a plot for `shot_distance`. You can use `pd.crosstab(~)` or a similar plotting function."
      ],
      "metadata": {
        "id": "FIvtZWa-C4hd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 1: Plot `shot_distance`"
      ],
      "metadata": {
        "id": "pdbanTX-X8XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 1 EXERCISE\n",
        "\n",
        "# Define bins for shot distance\n",
        "distance_bins = [\n",
        "    ''' ADD YOUR CODE HERE '''\n",
        "]\n",
        "\n",
        "# Group shots into distance bins\n",
        "distance_groups = <REMOVE ME AND MY BRACKETS>\n",
        "\n",
        "# Create a crosstab comparing distance range vs. shot_made_flag\n",
        "crosstab_result = <REMOVE ME AND MY BRACKETS>\n",
        "\n",
        "# Plot the crosstab as a bar chart\n",
        "crosstab_result.plot(<REMOVE ME AND MY BRACKETS>, figsize=(8, 4))\n",
        "plt.title(\"Shot Distance Range vs. Shot Outcome\")\n",
        "plt.xlabel(\"Distance Range (feet)\")\n",
        "plt.ylabel(\"Count of Shots\")\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2CJDXkdGXSnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 2: Plot `shot_type`"
      ],
      "metadata": {
        "id": "JlxSVdCGX3Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 2 EXERCISE\n",
        "\n",
        "# Plot 'shot_type' versus the target variable 'shot_made_flag'\n",
        "''' ADD YOUR CODE HERE '''"
      ],
      "metadata": {
        "id": "Z7vOseagX3cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Logistic Regression?"
      ],
      "metadata": {
        "id": "EzLWHOQBnT-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANALYSIS: What is logistic regression?\n",
        "\n",
        "Tasks:\n",
        "1. Run the logistic regression code, analyze the code and the output."
      ],
      "metadata": {
        "id": "qhKKPIm-b0CQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 1: Run and Analyze the Logistic Regression Code"
      ],
      "metadata": {
        "id": "LJy2mEnAb_aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 1 EXERCISE AND SOLUTION\n",
        "\n",
        "# Selecting one feature (shot_distance) for logistic regression\n",
        "X = KobeDataset[['shot_distance']]  # Only using shot distance as the feature\n",
        "y = KobeDataset['shot_made_flag']\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression Model (without standardization)\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predicting and evaluating the model\n",
        "y_pred = log_reg.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.5f}\")\n",
        "\n",
        "# Visualizing the sigmoid function and the threshold\n",
        "def plot_sigmoid(X, model):\n",
        "\n",
        "    # Create a range of shot distances for smooth plotting\n",
        "    X_range = np.linspace(X.min(), X.max(), 300).reshape(-1, 1)\n",
        "\n",
        "    # Get predicted probabilities for this range\n",
        "    y_proba = model.predict_proba(X_range)[:, 1]\n",
        "    # print(y_proba)\n",
        "\n",
        "    # Plotting the sigmoid curve\n",
        "    plt.plot(X_range, y_proba, label=\"Predicted Probability (Sigmoid)\", color=\"blue\")\n",
        "    plt.scatter(X_train, y_train, label=\"Training Data\", alpha=0.5, color=\"red\")\n",
        "    plt.axhline(0.5, color='green', linestyle='--', label=\"Threshold (0.5)\")\n",
        "    plt.title(\"Logistic Regression: Sigmoid Function for Shot Distance\")\n",
        "    plt.xlabel(\"Shot Distance\")\n",
        "    plt.ylabel(\"Predicted Probability of Shot\")\n",
        "    plt.legend(loc = 'lower left')\n",
        "    plt.show()\n",
        "\n",
        "# Plot the sigmoid curve\n",
        "plot_sigmoid(X, log_reg)"
      ],
      "metadata": {
        "id": "IQk1Qz82na0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** For our initial logistic regression fit, what are the chosen input and output?"
      ],
      "metadata": {
        "id": "oddM_8AdqcBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "HF8a_ziwqgZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** Use the generated plot to answer the following question: what is fit in a Logistic Regression?"
      ],
      "metadata": {
        "id": "HN3ytqT3qrmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*FOR ANSWER REFER TO NOTION!*"
      ],
      "metadata": {
        "id": "uZY7Sru9qwua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** Use the generated plot to answer the following question: how are predictions made in Logistic Regression?"
      ],
      "metadata": {
        "id": "rbonW6DTW1gI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*FOR ANSWER REFER TO NOTION!*"
      ],
      "metadata": {
        "id": "ybWtcD5ZW1oV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE: Train a Baseline Model\n",
        "\n",
        "Tasks:\n",
        "1. Fit a `LogisticRegression()` model with your own set of features. Make sure to look at the accuracy of your model and compare it to the simple case we showed above."
      ],
      "metadata": {
        "id": "oPRW9UNQGqe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 1: Fit your own `LogisticRegression()` with your own set of Features"
      ],
      "metadata": {
        "id": "21C_v1LypzYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 1 EXERCISE\n",
        "\n",
        "''' ADD YOUR CODE HERE '''"
      ],
      "metadata": {
        "id": "Zu92f0AMr29P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** Review the concepts of one-hot and multi-hot encoding through the concept pages on Notion. Then, given the following feature of a dataset, usually a column vector (5 rows x 1 column;5 data points x 1 feature). Convert this to a one-hot representation. What would the one-hot representation of the following set of 5 samples be?"
      ],
      "metadata": {
        "id": "I6BKoTcZqU3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "XP7EXMAIqVLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "voUE5AoVe9VO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5roRTpkb72I"
      },
      "source": [
        "### EXERCISE: Encode Categorical Data\n",
        "\n",
        "Tasks:\n",
        "1. Encode the `shot_zone_basic` feature into one-hot encoding using the method `pd.get_dummies(~, prefix = \"shot_zone\")`. Then, identify the shot_zone for the 979th datapoint using the `.iloc(~)` method.\n",
        "2. Train a `LogisticRegression()` model with this new feature. You can add the new feature using the `df.join(~)` method. How many extra columns were created for this new variable? Did the accuracy improve?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 1: Generate a One-Hot Vector Encoding of `shot_zone_basic`"
      ],
      "metadata": {
        "id": "pZ3HJOXbwbwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 1 EXERCISE\n",
        "\n",
        "# Display the frequency of each category in the 'shot_zone_basic' column\n",
        "print(KobeDataset[\"shot_zone_basic\"].value_counts())\n",
        "print('\\n')\n",
        "\n",
        "# Generate one-hot encoded columns for each category in 'shot_zone_basic'\n",
        "# and use 'shot_zone' as the prefix for the new columns\n",
        "shot_zones = <REPLACE ME AND MY ARROWS>\n",
        "\n",
        "# Show the first five rows of the resulting one-hot encoded DataFrame\n",
        "shot_zones.head(5)\n",
        "\n",
        "# Check the shot_zone for datapoint 979\n",
        "''' ADD YOUR CODE HERE '''"
      ],
      "metadata": {
        "id": "3c9ybtjbwb4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TASK 2: Train your own `LogisticRegression()` with this new Categorical Variable"
      ],
      "metadata": {
        "id": "ipwrwTjiyCjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 2 EXERCISE\n",
        "\n",
        "# Add this New Feature to your Dataset\n",
        "KobeDataset.shape\n",
        "KobeDataset = <REPLACE ME AND MY BRACKETS>\n",
        "KobeDataset.shape\n",
        "\n",
        "# Look at your New Columns\n",
        "print(list(KobeDataset.columns))\n",
        "\n",
        "# TRAIN A NEW LOGISTIC REGRESSION ----------------------------------------------\n",
        "\n",
        "''' ADD YOUR CODE HERE '''"
      ],
      "metadata": {
        "id": "LYCmii4fyCr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** What potential issues might arise from using one-hot encoding on a feature with many unique categories?"
      ],
      "metadata": {
        "id": "l73zsfRxpYFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "3pK0jQIwpdNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** What is the purpose of the sigmoid function in logistic regression?"
      ],
      "metadata": {
        "id": "nrINszkqp2sD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "Z29bPzdEp2-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** What is the difference between numerical discrete and categorical nominal data types? Give an example of each from the Kobe Bryant dataset."
      ],
      "metadata": {
        "id": "9o4nJqKXpdiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "AIFK5r-updyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** In the context of the Kobe Bryant shot dataset, what are some examples of categorical features that might benefit from one-hot encoding?"
      ],
      "metadata": {
        "id": "bn9VB3K7pp_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "IKZ-tLJJpqRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** How does one-hot encoding work, and when should it be used?"
      ],
      "metadata": {
        "id": "T1zLW0ucpq6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "Sj4UPE50prKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCUSSION QUESTION:** What is feature engineering and why is it important in machine learning?"
      ],
      "metadata": {
        "id": "iqs4JisiqGgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*YOUR ANSWER HERE:*"
      ],
      "metadata": {
        "id": "wLIjgtQcqGyt"
      }
    }
  ]
}